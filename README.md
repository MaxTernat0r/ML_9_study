# [Информатика Силаэдра](https://codingprojects.ru): полный сборник
По мере надобности сдачи тасков здесь появляется все за 9 класс, чуть позже появляются построчные объяснения каждого скрипта.
Делаю в удобном для себя темпе, используйте без ограничений.
В ближайшее время начнет появляться 10 класс, за ним вероятно еще какие-то. 

# FAQ ML (9 класс):
### Что нужно для работы?
Win + R, в появившемся окне "cmd". В консоль вводите:
```pip install jupyter```
```pip install numpy```
```pip install scikit-learn```
```pip install pandas matplotlib```
### Как открыть тетрадку?
В проводнике находите директорию с тетрадкой, нажимаете по пустому пространству в проводнике и выбираете "Открыть в Терминале". Далее вводите ```jupyter notebook```. С шансом 99% датасет (при наличии) должен лежать в той же папке, что и тетрадка.
## Терминология за все уроки:
* Модель - математическое описание некоторого явления.
* Машинное обучение - область искусственного интеллекта, изучающая программы и модели, способные обучатся на данных (примерах).
* Датасет - набор данных (примеров) в виде значений признаков и целевой переменной.
* Признак - численная характеристика, описывающая изучаемый объект.
* Целевая переменная - численная характеристика объекта, которую мы пытаемся предсказать.
* Апроксимация - примерное приближение зависимости в данных какой-либо более простой функцией.
* Регрессия - предсказание непрерывной числовой величины.
* Линейная зависимость - зависимость вида y = kx + b.
* Линейная регрессия - регрессия на основе предположения о линейной зависимости целевой переменной и признаков (апроксимация зависимости линейной функцией).
* Метод наименьших квадратов - подбор таких значений коэффициентов, при которых сумма квадратов ошибок при предсказании на обучающей выборке минимален.
* Метрика качества модели - функция, с помощью которой мы вычисляем, насколько хорошо работает модель.
* Метрика RMSE - корень из среднеквадратичного отклонения предсказания модели от истиного значения. Показывает, насколько в среднем модель ошибается при предсказании.
* Метрика R-relative-MSE - корень из среднеквадратичного отклонения предсказания модели от истиного значения, деленного на истиное значение. Показывает, на сколько процентов мы в среднем ошибаемся.
* Гистограмма - график, который для каждого значения в наборе показывает, сколько раз оно в нем встречается. По оси X - числа или объекты, по оси Y - количество таких чисел в наборе.
* Нормальное распределение в наборе чисел - это когда больше всего чисел близки к среднему, а чем меньше число похоже на среднее, тем реже оно встречается. Гистограмма нормального распределения похожа на колокол.
* Среднее арифметическое - сумма всех чисел в наборе, деленная на количество.
* Стандартное отклонение - величина, которая показывает, на сколько в среднем числа в наборе отличаются от среднего (мера "разброса"). Для нормального распредление 68% данных отличаются от среднего не более чем на 1 нормальное распределение.
* Масштабирование признака - одинаковое изменение всех значений признака. Часто применяется нормирование - масштабирование, при котором среднее значение в наборе приводится к нулю, а стандартное отклонение - к 1.
* DataFrame - тип данных библиотеки pandas (табличка).
* Дерево решений - дерево логических операций с признаками, с помощью которого можно прийти к ответу.
* Обучающая выборка - часть датасета, на которой модель обучается (во время обучения модель ВИДИТ эту часть датасета).
* Проверочная выборка - другая часть датасета, на которой точность модели проверяется (во время проверки модель НЕ ВИДИТ эту часть датасета).
* Регрессия - задача предсказания непрерывной величины.
* Классификация - задача, в которой количество вариантов ответа ограничено.
* Бинарная классификация - классификация, у которой всего два варинта ответа (например, это мужчина? - ответы только Да или Нет, как 1 и 0, поэтому бинарная).
* Многклассовая классификация - небинарная классификация, т.е. вариантов ответа больше чем два, но их числов все еще ограничено.
* Регуляризация модели - бывает так, что модель "переобучается", т.е. выдает очень точное предсказание на данных, которые уже видел, и неточное на данных, которые видит впервые. Тогда применяется классификация - модель работает менее точно, но в большем кол-ве случаев.
* Ансамблевая классификация - возьмем вместо одной умной модели средние результаты большего кол-ва тупых. Наудивление, тупые будут точнее умных. Это и есть ансамблевая классификация.
* Случайный лес - ансамблевая классификация для деревьев. То есть это буквально лес: много-много деревьев, каждое делает предсказание, средний результат всех деревье и будет ответом.

